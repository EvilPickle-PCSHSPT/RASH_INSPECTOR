{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mping\n",
    "from skimage import exposure\n",
    "from skimage.util import random_noise\n",
    "from skimage import transform\n",
    "import glob\n",
    "import random\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Zoom function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build from https://stackoverflow.com/questions/37119071/scipy-rotate-and-zoom-an-image-without-changing-its-dimensions/37121993#37121993"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "\n",
    "def clipped_zoom(img, zoom_factor, **kwargs):\n",
    "\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    # For multichannel images we don't want to apply the zoom factor to the RGB\n",
    "    # dimension, so instead we create a tuple of zoom factors, one per array\n",
    "    # dimension, with 1's for any trailing dimensions after the width and height.\n",
    "    zoom_tuple = (zoom_factor,) * 2 + (1,) * (img.ndim - 2)\n",
    "\n",
    "    # Zooming out\n",
    "    if zoom_factor < 1:\n",
    "\n",
    "        # Bounding box of the zoomed-out image within the output array\n",
    "        zh = int(np.round(h * zoom_factor))\n",
    "        zw = int(np.round(w * zoom_factor))\n",
    "        top = (h - zh) // 2\n",
    "        left = (w - zw) // 2\n",
    "\n",
    "        # Zero-padding\n",
    "        out = np.zeros_like(img)\n",
    "        out[top:top+zh, left:left+zw] = zoom(img, zoom_tuple, **kwargs)\n",
    "\n",
    "    # Zooming in\n",
    "    elif zoom_factor > 1:\n",
    "\n",
    "        # Bounding box of the zoomed-in region within the input array\n",
    "        zh = int(np.round(h / zoom_factor))\n",
    "        zw = int(np.round(w / zoom_factor))\n",
    "        top = (h - zh) // 2\n",
    "        left = (w - zw) // 2\n",
    "\n",
    "        out = zoom(img[top:top+zh, left:left+zw], zoom_tuple, **kwargs)\n",
    "\n",
    "        # `out` might still be slightly larger than `img` due to rounding, so\n",
    "        # trim off any extra pixels at the edges\n",
    "        trim_top = ((out.shape[0] - h) // 2)\n",
    "        trim_left = ((out.shape[1] - w) // 2)\n",
    "        out = out[trim_top:trim_top+h, trim_left:trim_left+w]\n",
    "\n",
    "    # If zoom_factor == 1, just return the input array\n",
    "    else:\n",
    "        out = img\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skin_aug(src, output):\n",
    "    for i, img in enumerate(glob.glob((src))):\n",
    "        \"\"\"\n",
    "        Operation\n",
    "        \"\"\"\n",
    "        #original\n",
    "        image = mping.imread(img)\n",
    "        #image = resize(image, (224, 224))\n",
    "        \n",
    "        #flip\n",
    "        horizontal = np.fliplr(image)\n",
    "        vertical = np.flipud(image)\n",
    "        allflip = np.flipud(horizontal)\n",
    "        \n",
    "        #zoom\n",
    "        zoom70 = clipped_zoom(image, 0.7)\n",
    "        zoom80 = clipped_zoom(image, 0.8)\n",
    "        zoom90 = clipped_zoom(image, 0.9)\n",
    "        zoom110 = clipped_zoom(image, 1.1)\n",
    "        zoom120 = clipped_zoom(image, 1.2)\n",
    "        zoom130 = clipped_zoom(image, 1.3)\n",
    "        \n",
    "        #rotate\n",
    "        rotate90 = transform.rotate(image, 90)\n",
    "        rotate270 = transform.rotate(image, 270)\n",
    "        rd_rotate = transform.rotate(image, random.uniform(0, 360))\n",
    "        \n",
    "        #light\n",
    "        bright = exposure.adjust_gamma(image, gamma=0.5, gain=1)\n",
    "        dark = exposure.adjust_gamma(image, gamma=1.5, gain=1)\n",
    "        z80_bright = exposure.adjust_gamma(zoom80, gamma=0.5, gain=1)\n",
    "        z120_bright = exposure.adjust_gamma(zoom120, gamma=0.5, gain=1)\n",
    "        z80_dark = exposure.adjust_gamma(zoom80, gamma=1.5, gain=1)\n",
    "        z120_dark = exposure.adjust_gamma(zoom120, gamma=1.5, gain=1)\n",
    "        \n",
    "        #noise\n",
    "        rd_noise = random_noise(image) \n",
    "        noise_bright = random_noise(bright) \n",
    "        noise_dark = random_noise(dark)\n",
    "        noise_allflip = random_noise(allflip)\n",
    "        noise_rd_rotate = random_noise(rd_rotate)\n",
    "        noise_z120 = random_noise(zoom120)\n",
    "        \n",
    "        \"\"\"\n",
    "        Save Images\n",
    "        \"\"\"\n",
    "        \n",
    "        #original\n",
    "        plt.imsave(output.format('o', i), image)\n",
    "        \n",
    "        #flip\n",
    "        plt.imsave(output.format('h', i), horizontal)\n",
    "        plt.imsave(output.format('v', i), vertical)\n",
    "        plt.imsave(output.format('af', i), allflip)\n",
    "        \n",
    "        #zoom\n",
    "        plt.imsave(output.format('z70', i), zoom70)\n",
    "        plt.imsave(output.format('z80', i), zoom80)\n",
    "        plt.imsave(output.format('z90', i), zoom90)\n",
    "        plt.imsave(output.format('z110', i), zoom110)\n",
    "        plt.imsave(output.format('z120', i), zoom120)\n",
    "        plt.imsave(output.format('z130', i), zoom130)\n",
    "        \n",
    "        #rotate\n",
    "        plt.imsave(output.format('rt90', i), rotate90)\n",
    "        plt.imsave(output.format('rt270', i), rotate270)\n",
    "        plt.imsave(output.format('rdrt', i), rd_rotate)\n",
    "        \n",
    "        #light\n",
    "        plt.imsave(output.format('b', i), bright)\n",
    "        plt.imsave(output.format('d', i), dark)\n",
    "        plt.imsave(output.format('z80b', i), z80_bright)\n",
    "        plt.imsave(output.format('z120b', i), z120_bright)\n",
    "        plt.imsave(output.format('z80d', i), z80_dark)\n",
    "        plt.imsave(output.format('z120d', i), z120_dark)\n",
    "        \n",
    "        #noise\n",
    "        plt.imsave(output.format('rdn', i), rd_noise)\n",
    "        plt.imsave(output.format('nb', i), noise_bright)  \n",
    "        plt.imsave(output.format('nd', i), noise_dark)\n",
    "        plt.imsave(output.format('naf', i), noise_allflip)\n",
    "        plt.imsave(output.format('nrt', i), noise_rd_rotate)\n",
    "        plt.imsave(output.format('nz120', i), noise_z120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = '/Users/waranthornchansawang/Desktop/RASH_INSPECTOR/Dataset/ORGAN/step4_split_data/arm/train/AD/*.jpg'\n",
    "out_path = '/Users/waranthornchansawang/Desktop/RASH_INSPECTOR/Dataset/ORGAN/step5_augmented_data/arm/AD/arm_{}_{}.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "skin_aug(src_path, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
