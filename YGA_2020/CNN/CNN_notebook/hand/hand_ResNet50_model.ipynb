{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hand_ResNet50_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/filmer2002/RASH_INSPECTOR/blob/master/hand_ResNet50_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSU5IxeVFPJC",
        "colab_type": "text"
      },
      "source": [
        "# **ResNet50**\n",
        "Let's implement !!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUeou-EuzZYm",
        "colab_type": "code",
        "outputId": "aca44b57-1030-4d18-fdca-8cbe02dd2541",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import models\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from keras.applications.resnet import ResNet50\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "from keras.preprocessing import image\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
        "from vis.utils import utils\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import PIL\n",
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzIgpJ-bzgPH",
        "colab_type": "code",
        "outputId": "f86a9966-e413-4d6f-d4da-0922228abd16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMXTr8Qtzr9L",
        "colab_type": "code",
        "outputId": "c009f820-041d-46d4-f8b1-98f5796d9d21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!git clone https://github.com/filmer2002/RASH_INSPECTOR_data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'RASH_INSPECTOR_data' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ai59Trpk0U_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_path = '/content/RASH_INSPECTOR_data/hand/train'\n",
        "val_path = '/content/RASH_INSPECTOR_data/hand/val'\n",
        "test_path = '/content/RASH_INSPECTOR_data/hand/test'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWOr2S6h0cnq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_size = 224\n",
        "epochs = 50\n",
        "batch_size = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_JbSzFY0ekw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_norm = ImageDataGenerator(rescale=1. / 255) \n",
        "val_norm = ImageDataGenerator(rescale=1. / 255) \n",
        "test_norm = ImageDataGenerator(rescale=1. / 255) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbCyh1vm0hc7",
        "colab_type": "code",
        "outputId": "50bdd75b-cfa9-4691-9269-65d59df615ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "train_generator = train_norm.flow_from_directory( \n",
        "    train_path, \n",
        "    target_size=(img_size, img_size), \n",
        "    batch_size=batch_size)\n",
        "\n",
        "val_generator = val_norm.flow_from_directory( \n",
        "    val_path, \n",
        "    target_size=(img_size, img_size), \n",
        "    batch_size=batch_size)\n",
        "\n",
        "test_generator = test_norm.flow_from_directory( \n",
        "    test_path, \n",
        "    target_size=(img_size, img_size), \n",
        "    batch_size=batch_size,\n",
        "    shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400 images belonging to 2 classes.\n",
            "Found 50 images belonging to 2 classes.\n",
            "Found 50 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1HwBtpH0mb6",
        "colab_type": "code",
        "outputId": "85bf5887-eb71-4f81-cfd4-115eae0d5382",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "num_train_files = len(train_generator.filenames)\n",
        "num_train_classes = len(train_generator.class_indices)\n",
        "print('num_train_files', num_train_files, '&', 'num_train_classes', num_train_classes )\n",
        "\n",
        "num_val_files = len(val_generator.filenames)\n",
        "num_val_classes = len(val_generator.class_indices)\n",
        "print('num_val_files', num_val_files, '&', 'num_val_classes', num_val_classes )\n",
        "\n",
        "num_test_files = len(test_generator.filenames)\n",
        "num_test_classes = len(test_generator.class_indices)\n",
        "print('num_test_files', num_test_files, '&', 'num_test_classes', num_test_classes )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num_train_files 400 & num_train_classes 2\n",
            "num_val_files 50 & num_val_classes 2\n",
            "num_test_files 50 & num_test_classes 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwY7ZXJn0ocN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_steps = np.ceil(num_train_files/batch_size)\n",
        "val_steps = np.ceil(num_val_files/batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vPX8W5L0ql5",
        "colab_type": "code",
        "outputId": "3925a894-1460-4154-c9e6-b176615d783f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "model = ResNet50(weights='imagenet')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
            "102973440/102967424 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1XeMUWT0ugn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = model.layers[-2].output\n",
        "predictions = Dense(num_train_classes, activation='softmax')(x)\n",
        "model = Model(inputs=model.input, outputs=predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXhzRdfA0u3u",
        "colab_type": "code",
        "outputId": "e2e9b4b1-c83b-4bf1-9767-877c5f60091d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (GlobalAveragePooling2 (None, 2048)         0           conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 2)            4098        avg_pool[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 23,591,810\n",
            "Trainable params: 23,538,690\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tF21Irz1Cok",
        "colab_type": "code",
        "outputId": "09c66d69-479d-4e98-e696-5f41876df044",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "model.compile(Adam(lr=0.01), \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5Huli8W1E92",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_path = '/content/drive/My Drive//RASH_INSPECTOR/ORGAN/hand/ResNet50/hand_resnet50_model.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khYEaVmT1J0B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint = ModelCheckpoint(model_path, monitor='val_acc', verbose=1,\n",
        "                             save_best_only=True, mode='max')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OiP64Mv1LIa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLOvVg7y1MTs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2,\n",
        "                              verbose=1, mode='max', min_lr=0.00001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18aO74K21OHn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log_dir = '/content/drive/My Drive//RASH_INSPECTOR/ORGAN/hand/ResNet50/tf-log/'\n",
        "tb_cb = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=0, batch_size=32, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None, embeddings_data=None, update_freq='epoch')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnnxJtXg1Wfr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cb_list = [checkpoint, early_stop, reduce_lr, tb_cb]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhU5kVpG1ZEE",
        "colab_type": "code",
        "outputId": "7de92035-dce4-4678-a4ff-d7dc708dd20a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit_generator(train_generator,\n",
        "                              steps_per_epoch=train_steps,\n",
        "                              validation_data=val_generator,\n",
        "                              validation_steps=val_steps,\n",
        "                              epochs=epochs,\n",
        "                              verbose=1,\n",
        "                              callbacks=cb_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1122: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1125: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "Epoch 1/50\n",
            "13/13 [==============================] - 16s 1s/step - loss: 1.5363 - acc: 0.5716 - val_loss: 8.0590 - val_acc: 0.5000\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.50000, saving model to /content/drive/My Drive//RASH_INSPECTOR/ORGAN/hand/ResNet50/hand_resnet50_model.h5\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1265: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n",
            "Epoch 2/50\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.9373 - acc: 0.5938 - val_loss: 8.0590 - val_acc: 0.5000\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.50000\n",
            "Epoch 3/50\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 1.2938 - acc: 0.5985 - val_loss: 8.0590 - val_acc: 0.5000\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.50000\n",
            "\n",
            "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
            "Epoch 4/50\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.7755 - acc: 0.6245 - val_loss: 8.0590 - val_acc: 0.5000\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.50000\n",
            "Epoch 5/50\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.9021 - acc: 0.6155 - val_loss: 8.0590 - val_acc: 0.5000\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.50000\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
            "Epoch 6/50\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.8503 - acc: 0.6372 - val_loss: 6.5507 - val_acc: 0.5600\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.50000 to 0.56000, saving model to /content/drive/My Drive//RASH_INSPECTOR/ORGAN/hand/ResNet50/hand_resnet50_model.h5\n",
            "Epoch 7/50\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.8444 - acc: 0.6415 - val_loss: 4.1206 - val_acc: 0.7000\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.56000 to 0.70000, saving model to /content/drive/My Drive//RASH_INSPECTOR/ORGAN/hand/ResNet50/hand_resnet50_model.h5\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
            "Epoch 8/50\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.6875 - acc: 0.6680 - val_loss: 2.3041 - val_acc: 0.6800\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.70000\n",
            "Epoch 9/50\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.8985 - acc: 0.6369 - val_loss: 1.3816 - val_acc: 0.7600\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.70000 to 0.76000, saving model to /content/drive/My Drive//RASH_INSPECTOR/ORGAN/hand/ResNet50/hand_resnet50_model.h5\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.599999814061448e-05.\n",
            "Epoch 10/50\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.7233 - acc: 0.6421 - val_loss: 1.3704 - val_acc: 0.7400\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.76000\n",
            "Epoch 11/50\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 1.0219 - acc: 0.6436 - val_loss: 1.1074 - val_acc: 0.7200\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.76000\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "Epoch 12/50\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 0.8043 - acc: 0.6491 - val_loss: 0.9353 - val_acc: 0.7200\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.76000\n",
            "Epoch 13/50\n",
            "13/13 [==============================] - 3s 227ms/step - loss: 0.7800 - acc: 0.6534 - val_loss: 0.7955 - val_acc: 0.7400\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.76000\n",
            "Epoch 14/50\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.8579 - acc: 0.6563 - val_loss: 0.7962 - val_acc: 0.7400\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.76000\n",
            "Epoch 15/50\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.7474 - acc: 0.6534 - val_loss: 0.7974 - val_acc: 0.7400\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.76000\n",
            "Epoch 16/50\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.8305 - acc: 0.6704 - val_loss: 0.7982 - val_acc: 0.7400\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.76000\n",
            "Epoch 17/50\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.7961 - acc: 0.6413 - val_loss: 0.7991 - val_acc: 0.7200\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.76000\n",
            "Epoch 18/50\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.7723 - acc: 0.6586 - val_loss: 0.7994 - val_acc: 0.7200\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.76000\n",
            "Epoch 19/50\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.8511 - acc: 0.6517 - val_loss: 0.7994 - val_acc: 0.7200\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.76000\n",
            "Epoch 20/50\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.7668 - acc: 0.6352 - val_loss: 0.7994 - val_acc: 0.7200\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.76000\n",
            "Epoch 21/50\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.7032 - acc: 0.6400 - val_loss: 0.7994 - val_acc: 0.7200\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.76000\n",
            "Epoch 22/50\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.7344 - acc: 0.6565 - val_loss: 0.7996 - val_acc: 0.7200\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.76000\n",
            "Epoch 23/50\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.6437 - acc: 0.6632 - val_loss: 0.7995 - val_acc: 0.7200\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.76000\n",
            "Epoch 00023: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtqO829W1a2Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights('/content/drive/My Drive//RASH_INSPECTOR/ORGAN/hand/ResNet50/hand_resnet50_weights.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-GGlMlc1hl0",
        "colab_type": "code",
        "outputId": "9084aa52-fc27-41fb-a05a-47e82e33d7d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model.load_weights(model_path)\n",
        "\n",
        "val_loss, val_acc = \\\n",
        "model.evaluate_generator(test_generator, \n",
        "                        steps=val_steps)\n",
        "\n",
        "print('val_loss:', val_loss)\n",
        "print('val_acc:', val_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "val_loss: 0.7630168437957764\n",
            "val_acc: 0.76\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7bR_Jqr1kzT",
        "colab_type": "code",
        "outputId": "c8dbc261-60e4-40ce-d619-e13c460d51e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.title('accuracy')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QG_wa7M61nUL",
        "colab_type": "code",
        "outputId": "efa9c73b-ea10-47ba-a50f-756b0db9c24d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.title('loss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEWCAYAAABsY4yMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkqIU8CIiKUoBLyKSohTwIiIp6v8Dgjd58eifICoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaUGNUhd1pAN",
        "colab_type": "code",
        "outputId": "c435ff86-b683-47c7-e4db-7dde33e5e41f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "Y_pred = model.predict_generator(test_generator, num_test_files//batch_size+1)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(test_generator.classes, y_pred))\n",
        "print('Classification Report')\n",
        "classes_names = ['AD', 'Other']\n",
        "print(classification_report(test_generator.classes, y_pred, target_names=classes_names))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix\n",
            "[[13 12]\n",
            " [ 0 25]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          AD       1.00      0.52      0.68        25\n",
            "       Other       0.68      1.00      0.81        25\n",
            "\n",
            "    accuracy                           0.76        50\n",
            "   macro avg       0.84      0.76      0.75        50\n",
            "weighted avg       0.84      0.76      0.75        50\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCJcDnY21uNe",
        "colab_type": "code",
        "outputId": "59ead92a-7eae-451e-c8fa-006dcfddd1d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predictions = model.predict_generator(test_generator, steps=val_steps, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 83ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTXfn0sb1wCQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EK4mhI0411MS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cm_plot_labels = ['AD', 'Other']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-m90UN3B12n1",
        "colab_type": "code",
        "outputId": "76a1ea4c-3eec-4e3d-8df9-31e1a33a6b7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "source": [
        "cm = confusion_matrix(test_generator.classes, predictions.argmax(axis=1))\n",
        "plot_confusion_matrix(cm, cm_plot_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[13 12]\n",
            " [ 0 25]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEYCAYAAACZaxt6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAfK0lEQVR4nO3debxVdbnH8c8XEERBUTFE0HDM0Kso\n6C3zdrW6WmaiXSey1LTIyiarG6YlVpY3h8q0Aa9TaUheNU0zMxtMcwLEGcExQQbRbuIACjz3j/U7\ntD2cYe+99j57Lc73zWu9zt5rrf1bz4bNefZvXIoIzMzM8ujT6gDMzKz8nEzMzCw3JxMzM8vNycTM\nzHJzMjEzs9ycTMzMLDcnEzOzXkrSFpL+KOlhSQ9J+lzaP1nSfEmz0rZ/t2V5nomZWe8kaTgwPCJm\nShoMzAAOAg4DXoqIs6otq1+TYjQzs4KLiAXAgvR4qaRHgBH1lOVmLjMzQ9IoYFfgrrTrBEn3S7pI\n0kbdvt7NXGZmxdd3gzdHrHi1ptfEq889BCyr2DUlIqa0P0/SIODPwOkRcbWkYcASIIBvkjWFHdvV\ntdzMZWZWArFiGQN2OKKm1yy794fLImJcV+dIWge4Crg8Iq4GiIhFFccvAK7v7lpu5jIzKwMBUm1b\nd0VKAi4EHomIcyr2D6847WDgwe7Kcs3EzKws1PDv/+8APgI8IGlW2vdVYIKkMWTNXE8Bn+iuICcT\nM7OyqKK2UYuIuI2sztPeb2oty8nEzKwU1IyaScM4mZiZlUWDayaN5GRiZlYGwjUTMzPLq7oRWq3i\nZGJmVhaumZiZWW6umZiZWT4ezWVmZnm1zYAvKCcTM7OycM3EzMzycTOXmZk1Qh83c5mZWR6etGhm\nZg3hDngzM8vHfSZmZtYIrpmYmVlurpmYmVkuVd6Kt1WcTMzMysI1EzMzy801EzMzy8ejuczMrBFc\nMzEzs1w8A97MzPJzM5eZmTWCm7nMzCw310zMzCw310zMzCwXuc/EzMwawTUTMzPLS04mZmaWh3Ay\nMTOzvJS2gnIyMTMrBblmYmZm+TmZmJlZbk4mZmaWW5GTSXFnwJh1QtJASb+W9A9JV+Yo50hJv2tk\nbK0i6d8kPdrqOKyJVMfWg5xMrGkkfUjSdEkvSVog6UZJezWg6EOAYcAmEXFovYVExOURsW8D4mkq\nSSFp267OiYi/RMRbeiom63lKHfC1bD3JycSaQtKJwPeBb5P94t8S+BEwvgHFvxmYExErGlBW6Uly\nc3Uv4WRivYqkDYFvAJ+OiKsj4uWIeD0ifh0RX07nDJD0fUnPpu37kgakY3tLmifpi5IWp1rNR9Ox\n04CvA4enGs9xkiZLuqzi+qPSt/l+6fkxkp6QtFTSk5KOrNh/W8Xr9pR0T2o+u0fSnhXH/iTpm5Ju\nT+X8TtLQTt5/W/z/VRH/QZL2lzRH0guSvlpx/h6S7pD0f+nc8yT1T8duTafdl97v4RXlf0XSQuDi\ntn3pNduka+yWnm8u6TlJe+f6h7WWczKx3ubtwLrANV2cczLwNmAMsAuwB3BKxfHNgA2BEcBxwPmS\nNoqIU8lqO9MiYlBEXNhVIJLWB84F3hcRg4E9gVkdnLcxcEM6dxPgHOAGSZtUnPYh4KPAm4D+wJe6\nuPRmZH8HI8iS3wXAh4GxwL8BX5O0VTp3JfAFYCjZ3927gU8BRMQ70zm7pPc7raL8jclqaRMrLxwR\njwNfAS6TtB5wMXBpRPypi3itBJxMrLfZBFjSTTPUkcA3ImJxRDwHnAZ8pOL46+n46xHxG+AloN4+\ngVXATpIGRsSCiHiog3PeD8yNiJ9HxIqImArMBj5Qcc7FETEnIl4FfkmWCDvzOnB6RLwOXEGWKH4Q\nEUvT9R8mS6JExIyIuDNd9yngp8C/V/GeTo2I5SmeN4iIC4DHgLuA4WTJ28rMHfDWCz0PDO2mLX9z\n4OmK50+nfavLaJeMXgEG1RpIRLwMHA4cDyyQdIOkHaqIpy2mERXPF9YQz/MRsTI9bvtlv6ji+Ktt\nr5e0vaTrJS2U9CJZzavDJrQKz0XEsm7OuQDYCfhhRCzv5lwrAddMrLe5A1gOHNTFOc+SNdG02TLt\nq8fLwHoVzzerPBgRN0XEf5B9Q59N9ku2u3jaYppfZ0y1+DFZXNtFxAbAV+n+e2V0dVDSILIBEBcC\nk1MznpVYM0ZzSdpC0h8lPSzpIUmfS/s3lnSzpLnp50bdleVk0rtcBCwGHqzY903gfrJ+hN/xxtpB\nXSLiH2T9BOenjuf1JK0j6X2SvptOmwqcImnT1JH9deCyzsrsxizgnZK2VNb5f1LbAUnDJI1PfSfL\nyZrLVnVQxm+A7ZUNZ+4n6XBgNHB9nTHVYjDwIvBSqjV9st3xRcDWNZb5A2B6RHyMrC/oJ7mjBCRd\nlAYVPFix70xJsyXdL+kaSUMacS1bUxNqJiuAL0bEaLI+zE9LGg1MAm6JiO2AW9LzLjmZ9C6XAO9t\nt+9MYGey9v/ryX6p5xYRZwMnknWqPwc8A5wA/Cqd8i1gOlkiewCYmfbVc62bgWmprBm8MQH0SXE8\nC7xA1hfR/pc1EfE8cADwRbJmuv8CDoiIJfXEVKMvkXXuLyWrNU1rd3wycKmy0V6HdVeYpPFk/85t\n7/NEYDelUWw5XcKan6GbgZ0iYmdgDhXJ3BqswX0mqQ9xZnq8FHiErGl3PHBpOu1Sum5lyEKL6LK2\nbGufUWS/bHfq4NhJZE07a/yyNWsjaRRwfUSs8RmSdDBwSEQ0InFZhXU23SY2Hn9GTa9ZfOFhMyJi\nXDXnpn/XW8l+N/wtIoak/QL+3va8M57sZACnA0cB/wD2aXEsVm7HsmbNyhqkjk71oZKmVzyfEhFT\nOih3EHAV8PmIeLHyOhERkrqtdRSymSu1s0fbqBtlk9BelXSvpEck3S3pmBaHuTY5GdgCuJysKcqs\nZpJOJmuDv7zVsayt6ugzWRIR4yq2jhLJOmSJ5PKIuDrtXiRpeDo+nKyvtUuFTCbABOC29LPN4xGx\na0S8FTgC+LzSrGhrmMuB/2x1EFY+6cvdAcCR4bbzpmjSaC6Rjfh7JCLOqTh0HXB0enw0cG13ZRUu\nmaTq1l5ks56P6OiciHiCrFPxsz0Y2tpqu4rH48mGqJpVTdJ7yQYsHBgRr7Q6nrVa4yctvoNssvC7\nJM1K2/7AGcB/SJoLvCc971IR+0zGA7+NiDmSnpc0lmx0TXszgY4mn1nnpgJ7k02ImwecCuxPNrN8\nFdkkveNbFZwVn6TVnyFla4GdSjZwYwBwc/o2fGdE+HPUaGr8/Uwi4jY6TzvvrqWsIiaTCWRj5CFb\nhmICcF4H53X6typpImm9on4DBo4dMmKrzk7tzUYA/9Nu37+QJRlL+vYp7s2IWmHYtjtWPm3/GRqZ\nfu6y2XY7faLHgiq4RY89tCQiNm1EWY1OJo1UqGSibJbuu4B/SaMH+pLN9D2/g9N3JRsTvYbUyTQF\nYNNtdozx3/HgEqvPkIGF+i9iJXT2gW9tv0xP3YqcTIrWZ3II8POIeHNEjIqILYAnyUYarZbGQ58F\n/LDHIzQza5UCL/RYtK9dE4D/brfvKrI22W0k3Uu2rPdS4NyIuKRnwzMza50i10wKlUwiYo0JcxFx\nLtk9JszMeq0a1ttqiUIlEzMz65yTiZmZ5eZkYmZm+RU3lziZmJmVhWsmZmaWTxNmwDeSk4mZWQkI\nKHAucTIxMysHDw02M7MGKHAucTIxMysL10zMzCwfuWZiZmY5CehT4FsiOJmYmZWEayZmZpab+0zM\nzCwf95mYmVle2aTF4mYTJxMzs1LwpEUzM2uAAucSJxMzs7JwzcTMzPJxB7yZmeXlDngzM2uIAucS\nJxMzs7JwzcTMzHIrcC5xMjEzKwXfttfMzPLybXvNzKwBPAPezMwaoMC5xMnEzKwsXDMxM7N8PAPe\nzMzy8gx4MzNrCCcTMzPLrcC5xMnEzKwsXDMxM7N83AFvZmZ5yZMWzcysEQqcS5xMzMzKok+Bs4mT\niZlZSRQ4l9Cn1QGYmVn3lJagr2XrvkxdJGmxpAcr9k2WNF/SrLTtX018TiZmZiXRR7VtVbgEeG8H\n+78XEWPS9ptqCnIzl5lZSTR6NFdE3CppVCPKcs3EzKwkpNo2YKik6RXbxCovdYKk+1Mz2EbVvMDJ\nxMysBESaa1LDH2BJRIyr2KZUcakfA9sAY4AFwNnVxNdpM5ekDbp6YUS8WM0FzMysMarsB8klIha1\nPZZ0AXB9Na/rqs/kISDIEuLq66TnAWxZe5hmZlaXKkdo5b+MhkfEgvT0YODBrs5v02kyiYgtGhGY\nmZk1RqNziaSpwN5kfSvzgFOBvSWNIas0PAV8opqyqhrNJekIYOuI+LakkcCwiJhRR+xmZlYH0fgZ\n8BExoYPdF9ZTVrcd8JLOA/YBPpJ2vQL8pJ6LmZlZ/eoYzdVjqqmZ7BkRu0m6FyAiXpDUv8lxmZlZ\nO2VfNfh1SX3I2s+QtAmwqqlRmZnZG7SitlGLapLJ+cBVwKaSTgMOA05ralRmZraGUq8aHBE/kzQD\neE/adWhEVDVUzMzMGqe4qaT6tbn6Aq+TNXV51ryZWQsUuc+kmtFcJwNTgc2BkcAvJJ3U7MDMzOyf\nsqHBDV81uGGqqZkcBewaEa8ASDoduBf4TjMDMzOzCj00A75e1SSTBe3O65f2mZlZDypwLulyocfv\nkfWRvAA8JOmm9Hxf4J6eCc/MzNqUtWbSNmLrIeCGiv13Ni8cMzPrSFufSVF1tdBjXeuzmJlZc5S1\nZgKApG2A04HRwLpt+yNi+ybGZWZm7RQ3lVQ3Z+QS4GKy9/E+4JfAtCbGZGZm7UjZDPhatp5UTTJZ\nLyJuAoiIxyPiFLKkYmZmPajsqwYvTws9Pi7peGA+MLi5YZmZWXul7jMBvgCsD3yWrO9kQ+DYZgZl\nZmZrKnAuqWqhx7vSw6X88wZZZmbWg0TP94PUoqtJi9eQ7mHSkYj4YFMiMjOzNZX4fibn9VgUTbTl\nkIGc98GdWh2GldRGu5/Q6hDMVitln0lE3NKTgZiZWdeKfP+Pau9nYmZmLSRKWjMxM7NiKeXaXO1J\nGhARy5sZjJmZda7IyaSaOy3uIekBYG56voukHzY9MjMzWy2b1a6atp5UTX/OucABwPMAEXEfsE8z\ngzIzszWV/ba9fSLi6XZZbmWT4jEzs04UuP+9qmTyjKQ9gJDUF/gMMKe5YZmZWaXs5ljFzSbVJJNP\nkjV1bQksAn6f9pmZWQ8q9TyTiFgMHNEDsZiZWRcKXDGp6k6LF9DBGl0RMbEpEZmZ2RrUghte1aKa\nZq7fVzxeFzgYeKY54ZiZWWcKnEuqauZ6wy16Jf0cuK1pEZmZWYeKPGmxnuVUtgKGNToQMzPrXOlH\nc0n6O//sM+kDvABMamZQZma2pgLnkq6TibKZiruQ3fcdYFVEdHrDLDMza5IWzGqvRZfDllPi+E1E\nrEybE4mZWYuoxj89qZo5MLMk7dr0SMzMrFNZn0kJ1+aS1C8iVgC7AvdIehx4mew9RUTs1kMxmpkZ\nxW7m6qrP5G5gN+DAHorFzMy6UNY7LQogIh7voVjMzKwTbc1cRdVVMtlU0omdHYyIc5oQj5mZdUTF\nHhrcVQd8X2AQMLiTzczMelCftD5XtVt3JF0kabGkByv2bSzpZklz08+Nqomtq5rJgoj4RjWFmJlZ\nczWpmesS4DzgZxX7JgG3RMQZkial51/prqCuaiYFrlCZmfU+Um1bdyLiVrJVTSqNBy5Njy8FDqom\ntq5qJu+upgAzM+sJok/t3/GHSppe8XxKREzp5jXDImJBeryQKtdi7DSZRET7bGVmZi0i6uqAXxIR\n4+q9ZkSEpKpWPqln1WAzM+tpPTerfZGk4RGxQNJwYHE1LyryLYXNzKxCo0dzdeI64Oj0+Gjg2mpe\n5JqJmVkJ1NnM1XWZ0lRgb7K+lXnAqcAZwC8lHQc8DRxWTVlOJmZmJdHom2NFxIRODtU8AMvJxMys\nJIo8A97JxMysBESxO7mdTMzMykDlXTXYzMwKpLipxMnEzKwUsrW5iptOnEzMzEqiuKnEycTMrDQK\nXDFxMjEzKwe5A97MzPLx0GAzM2sI10zMzCy34qYSJxMzs3LwpEUzM8vLfSZmZtYQrpmYmVluxU0l\nTiZmZqVR4IqJk4mZWRlkfSbFzSZOJmZmJeGaiZmZ5STkmomZmeXlmomZmeXiPhMzM8tPrpmYmVkD\nOJmYmVlu7oA3M7NcsnvAtzqKzjmZmJmVhGsmZmaWm/tMzMwsN9dMzMwsF/eZmJlZA3g5FTMzy8uT\nFs3MrBEKnEucTMzMyiDrMyluOiny/emtyX5302/Zece3sOMO23Lmd89odThWAiOHDeG3Uz7LzKtO\nZsb/nsynJ+wNwMmf2J/Hb/oWd14xiTuvmMR+e41ubaBrKdW49STXTHqplStX8vnPfpobbryZESNH\nstfbdueAAw7kraP9S8A6t2LlKiadczWzZs9j0HoD+OsvvsItd80G4IeX/ZHv//yWFke4lituxcQ1\nk97qnrvvZptttmWrrbemf//+HHr4EVz/62tbHZYV3MIlLzJr9jwAXnplObOfXMjmmw5pcVS9h2r8\n05OcTHqpZ5+dz8iRW6x+PmLESObPn9/CiKxsthy+MWPeMpJ7HnwKgOOPeCd3TzuJn5x6JEMGD2xt\ncGspqbatJzU1mUgaKelaSXMlPS7pB5L6Sxojaf+K8yZL+lIzYzGzxll/YH+mnvUxvnzWVSx9eRkX\nXPkXRn9gMv96xBksXPIiZ5z4wVaHuFYqcp9J05KJJAFXA7+KiO2A7YFBwOnAGGD/Ll5e67X6Nqqs\n3mLzzUcwb94zq5/Pnz+PESNGtDAiK4t+/fow9ayPM+3G6Vz7h/sAWPzCUlatCiKCi66+nXE7vbnF\nUa6lCpxNmlkzeRewLCIuBoiIlcAXgI8B3wUOlzRL0uHp/NGS/iTpCUmfbStE0ocl3Z3O/Wlb4pD0\nkqSzJd0HvL2J72OtNG733Xnssbk89eSTvPbaa1w57Qref8CBrQ7LSuAnpx7Jo08u5NzL/rB632ZD\nN1j9ePy7duHhxxe0IrS1WpYfittn0szRXDsCMyp3RMSLkp4CLga2j4gTIGvmAnYA9gEGA49K+jGw\nLXA48I6IeF3Sj4AjgZ8B6wN3RcQXm/ge1lr9+vXjez84jw+8fz9WrlzJ0cccy+gdd2x1WFZwe47Z\nmiMP+FcemDOfO6+YBMCp513HYfuNY+e3jCQieHrBC3zmW1NbHOlayDPgq3ZDRCwHlktaDAwD3g2M\nBe7JWs0YCCxO568EruqoIEkTgYnp6UsD19GjzQx8LTB08tdPWTL566e0Og4ruD/MAl2yxve3odee\nx5JWxFMSDWvzK3AuaWoyeRg4pHKHpA2ALYEVHZy/vOLxSrLYBFwaESd1cP6y1HS2hoiYAkypJ+je\nSNL0iBjX6jisnPz56UFNyCaptWgp2e/dFfX+Wzazz+QWYD1JR8HqTvKzgUuARWTNWdWUcYikN6Uy\nNpbknj0z64Vq7TGpKfPsExFj8nwpaFoyiYgADgYOlTQXmAMsA74K/JGsw72yA76jMh4GTgF+J+l+\n4GZgeLNiNjMrsiLPM2lqn0lEPAN8oINDy4Hdu3jdThWPpwHTOjhnUCNiNMBNgpaPPz89oImjfYPs\nC3sAP03dBDUrUge8tUi9Hx4z8OenR9WeTYZKml7xfEoH/157RcT81J1ws6TZEXFrrRdyMjEzK4k6\n5o4s6a4fJCLmp5+LJV0D7AHUnEy8NpeZWUk0us9E0vqSBrc9BvYFHqwnNtdMbDVJSgMnzHLxZ6k5\nmtBnMgy4Js3j6wf8IiJ+W09BTia9mKThZCsJBPC3tMpA387m75hVqy2RSNocWBgRq1ocUvk1oQc+\nIp4AdmlEWU4mvZSk9wNfIUsky4C+kg6KiJecUKwRJB1NtkbfRN44Kdnq1NPrbdXCfSa9kKT9gG8A\np5Kt3nw08Cxwv6RBEbEyrfpsVhdJx5IN//92WibJchLFnmfiZNLLSNoZuBH4QkT8kWxZmoURcRRw\nG/ALSf3c3m21aPvyUfElZC/gUxXH3QrSAAVegd7JpBd6ErgGOK6tOUvSgHTsG8AA4E0ti85Kp11n\n+5YAEXEs8CPg15L6R8QKJ5QGKHA2cTLpJSRtBhARS4EPkfWXXZX2LU/fKJ8j+wi6VmJVq+hsPwE4\nX9L3JH0q3WLiduBuSQMioqMFXq0GRb6fiZNJLyBpB+DZ9J98YmrDnggslvTrim+WB5Mlk5dbGa+V\nj6QDgcOACcDOZHdTJSI+CjwC/Dmd5764HIrcZ+JqZ+/wEvBXYCHZKsx7ka139i3g88Blkm4ETgA+\nGhEvtixSK6vBZM1ah5AtZd5247tRETEhDUPHfXH5FDkTO5n0AhExT9LdwG5ko7cOBT4ODCH7T38R\n8E5gv7RSs1lVJPVJc0j+RnYH1UUR8Y507DPA9pK+EBG+j28jFDibOJms5SqasCaR3e54KLCArCni\nFuBrwGPAURExu2WBWimkGsaiiFglaQKwlaTfk9V8rwH6SNof2BQ4BjjafSWN0XYP+KJyMlnLRURU\ntFPPJbtB2VjgxIj4laTtgeci4u8tC9JKQdIWwJeB2yStB3yRLIFcB3wEuBB4O3A8sAQ4JiLqWufJ\nOuB7wFurpZrJa5IuI+sIPT8ifpWOzWlpcFYmS8iGlo8FtgIOj4iHJT0AnAV8NSIulvRzANdIGq/A\nucSjuXqTiHiUrLmrb/pmadYtSUMkvSkiXgX+QDaQYxjZYI4BEXEl2Ryln0o6ICJWOJE0SYHnmbhm\n0vvcCXyw1UFYqewK7ClpI7JJrZPJho/vAPynpCsj4ipJrwMewNE0PT93pBZOJr1MRMyWdEREvNLq\nWKzYJI0kG1a+ChhHdtOkj0XE85Kmkq3pNg4YKOnSiLiuddH2Du4zsUJxIrHuSBoPnES2AOhGZEPH\nTwf2kbQ4ImZIOp9s5ektgfUAz09qolast1ULJxMzewNJ+wBnks1mf4psQuJlZPOSngSOkbSAbA23\n2cCtnujaQwqcTZxMzKy9PYFzU+1j3dSs9SHgSmA42YjAXwCjgL0j4oXWhdq7uM/EzAqvYoLrSGCd\ntHt5Wl36b5KOA84hm+w6k+wOik+1Jtreqch9Jh4abGbAG9bN+l/gHZLGpn0haR3g/8j6ReZFxF/T\nLV+tBxV4ZLBrJma2hjvJlo4/PNVWpgOrJO0JbIJ/b7SGZ8CbWZlExMuSLgA+Bpwt6Q7gNbIVgSd4\n6Z1WKm42cTIxszVExHxJ3yWb8b4f8AJwcFpFwVqg7R7wReVkYmYdSsun/CVtVgAFziVOJmZmZeGa\niZmZ5eZ5JmZmll9xc4mTiZlZWRQ4lziZmJmVgTzPxMzMGqHIfSZeTsUKR9JKSbMkPSjpyjx3hZS0\nt6Tr0+MDJU3q4twhkj5VxzUmS/pStfvbnXOJpENquNYoSb6vem9V4PVUnEysiF6NiDERsRPZzOvj\nKw8qU/NnNyKui4gzujhlCFBzMjHrKQXOJU4mVnh/AbZN38gflfQz4EFgC0n7SrpD0sxUgxkEIOm9\nkmZLmknFLYolHSPpvPR4mKRrJN2Xtj2BM4BtUq3ozHTelyXdI+l+SadVlHWypDmSbgPe0t2bkPTx\nVM59kq5qV9t6j6TpqbwD0vl9JZ1Zce1P5P2LtPJr6zepdutJTiZWWJL6Ae8DHki7tgN+FBE7kt2D\n/BTgPRGxGzAdOFHSusAFwAeAscBmnRR/LvDniNgF2A14CJgEPJ5qRV+WtG+65h7AGGCspHdKGgsc\nkfbtD+xexdu5OiJ2T9d7BDiu4tiodI33Az9J7+E44B8RsXsq/+OStqriOrbWUs1/epI74K2IBkqa\nlR7/BbgQ2Bx4OiLuTPvfBowGblf2Faw/cAewA/BkRMwFkHQZMLGDa7wLOAogIlYC/5C0Ubtz9k3b\nven5ILLkMhi4pu32x5Kquff5TpK+RdaUNgi4qeLYLyNiFTBX0hPpPewL7FzRn7JhuvacKq5layGv\nzWVWu1cjYkzljpQwXq7cBdwcERPanfeG1+Uk4DsR8dN21/h8HWVdAhwUEfdJOgbYu+JYtDs30rU/\nExGVSQdJo+q4tlnTuZnLyupOshs4bQsgaX1J25Pdk3yUpG3SeRM6ef0twCfTa/tK2hBYSlbraHMT\ncGxFX8wISW8CbgUOkjRQ0mCyJrXuDAYWpJtMHdnu2KGS+qSYtwYeTdf+ZDofSdtLWr+K69harMh9\nJq6ZWClFxHPpG/5USQPS7lMiYo6kicANkl4hayYb3EERnwOmpFvRrgQ+GRF3SLo9Db29MfWbvBW4\nI9WMXgI+HBEzJU0D7gMWA/dUEfLXgLuA59LPypj+BtwNbAAcHxHLJP0PWV/KTGUXfw44qLq/HVtb\nFXmeif55p04zMyuqXceOiz/ffndNr9lwYN8ZETGuSSG9gWsmZmYl0Iq5I7VwMjEzK4sCZxMnEzOz\nkihyn4mTiZlZSRR5nomHBpuZlUQz1uZKyw89KumxrhZC7Y6TiZlZWTQ4m0jqC5xPtmzRaGCCpNH1\nhOZkYmZWEk1Ym2sP4LGIeCIiXgOuAMbXE5uTiZlZCbStzdXgGfAjgGcqns9L+2rmDngzsxKYOXPG\nTQPX0dAaX7aupOkVz6dExJRGxtXGycTMrAQi4r1NKHY+sEXF85FpX83czGVm1nvdA2wnaStJ/cnu\n01PNLRXW4JqJmVkvFRErJJ1Atkp1X+CiiHionrK80KOZmeXmZi4zM8vNycTMzHJzMjEzs9ycTMzM\nLDcnEzMzy83JxMzMcnMyMTOz3JxMzMwst/8H4ZxR9eaUR/8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}